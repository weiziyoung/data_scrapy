from scrapy.spiders import Spider
import pickle
from datetime import date


class BaseSpider(Spider):
    name = ''
    KEY_WORDS = [['岗位职责', '岗位描述', '工作内容', '职位描述'],
                 ['任职要求', '任职条件', '任职资格', '岗位要求', '资质要求'],
                 ['福利待遇', '薪资待遇', '薪酬福利', '薪资福利'],
                 ['工作时间'],
                 ['工作地址', '工作地点', '上班地址']]
    INSPECT_WORDS = ['档案', '文控', '文件管理', '图书管理']
    FILTER_WORDS = ['档案', '文件', '文控', '图书', '资料']
    city_list = ['沈阳', '长春', '哈尔滨', '南京', '武汉', '广州', '成都', '西安', '石家庄', '唐山', '太原', '大连',
                 '鞍山', '抚顺', '吉林', '齐齐哈尔', '徐州', '杭州', '福州', '南昌', '济南', '青岛', '淄博', '郑州',
                 '长沙', '贵阳', '昆明', '兰州', '邯郸', '保定', '张家口', '大同', '本溪', '丹东', '锦州', '阜新',
                 '辽阳', '鸡西', '鹤岗', '大庆', '伊春', '佳木斯', '牡丹江', '无锡', '常州', '苏州', '宁波', '合肥',
                 '淮南', '淮北', '厦门', '枣庄', '烟台', '潍坊', '泰安', '临沂', '开封', '洛阳', '平顶山', '安阳',
                 '新乡', '焦作', '黄石', '襄樊', '荆州', '株洲', '湘潭', '衡阳', '深圳', '汕头', '湛江', '西宁',
                 '秦皇岛', '邢台', '承德', '沧州', '廊坊', '衡水', '阳泉', '长治', '营口', '盘锦', '铁岭', '朝阳',
                 '葫芦岛', '四平', '辽源', '通化', '白山', '松原', '白城', '双鸭山', '七台河', '南通', '连云港', '淮阴',
                 '盐城', '扬州', '镇江', '泰州', '温州', '嘉兴', '湖州', '绍兴', '台州', '芜湖', '蚌埠', '马鞍山', '铜陵',
                 '安庆', '阜阳', '泉州', '漳州', '南平', '龙岩', '景德镇', '萍乡', '九江', '新余', '东营', '济宁', '威海',
                 '日照', '莱芜', '德州', '鹤壁', '濮阳', '许昌', '漯河', '南阳', '商丘', '十堰', '宜昌', '鄂州', '荆门',
                 '孝感', '黄冈', '邵阳', '岳阳', '常德', '益阳', '郴州', '永州', '怀化', '韶关', '珠海', '佛山', '江门',
                 '茂名', '肇庆', '惠州', '梅州', '阳江', '东莞', '中山', '潮州', '海口', '自贡', '攀枝花', '泸州', '德阳', '绵阳', '广元', '遂宁', '内江', '乐山', '南充', '宜宾', '六盘水', '遵义', '曲靖', '铜川', '宝鸡', '咸阳', '汉中', '白银', '天水', '北京', '上海', '天津', '重庆', '乌鲁木齐', '南宁', '柳州', '呼和浩特', '乌海', '赤峰', '银川', '贵港', '桂林', '梧州', '石嘴山', '克拉玛依']

    def start_requests(self):
        pass

    def parse(self, response):
        pass

    def parse_item(self, response):
        pass
